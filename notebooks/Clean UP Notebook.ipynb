{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23842aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29edb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pypianoroll\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb72c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "301816b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pretty_midi\n",
    "from midi2audio import FluidSynth\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pretty_midi\n",
    "import pickle\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import music21\n",
    "# import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "import json\n",
    "import IPython.display\n",
    "from datetime import datetime\n",
    "import mido\n",
    "root_dir = '../raw_data'\n",
    "from music_generator.data import get_npz_data, multitrack_to_midi, fetching_instrument_pianorolls\n",
    "from music_generator.midi import sample_multitrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c67873",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_npz_data(1000, data_path='../raw_data/lpd_5/lpd_5_cleansed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_transfo = multitrack_to_midi(data, save_path='../raw_data/midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3fddb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pianorolls = fetching_instrument_pianorolls(data, 'Piano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pianorolls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7be89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "resolution = 24\n",
    "for i in pianorolls:\n",
    "    test.append(sample_multitrack(data[0], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f5a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multitrack(multitrack, track, x_qnotes=4, y_qnotes=2):\n",
    "#     pianoroll = track.pianoroll\n",
    "    qnote = multitrack.resolution\n",
    "#     quarter_notes = int(pianoroll.shape[0]/qnote)\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(int(np.floor(quarter_notes/(x_qnotes+y_qnotes)))):\n",
    "        X_start = i*x_qnotes *qnote\n",
    "        X_end = ((i+1)*x_qnotes) *qnote\n",
    "        y_start = X_end\n",
    "        y_end = ((i+1)*x_qnotes + y_qnotes) *qnote\n",
    "        X.append(pianoroll[X_start:X_end])\n",
    "        y.append(pianoroll[y_start:y_end])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = sample_multitrack(data[0], pianorolls_dumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying sampling without func\n",
    "X = []\n",
    "y = []\n",
    "qnote = 24\n",
    "x_qnotes=8\n",
    "y_qnotes=4\n",
    "for pianoroll in pianorolls:\n",
    "    quarter_notes = int(pianoroll.shape[0]/qnote)\n",
    "    for i in range(int(np.floor(quarter_notes/(x_qnotes+y_qnotes)))):\n",
    "        X_start = i*x_qnotes *qnote\n",
    "        X_end = ((i+1)*x_qnotes) *qnote\n",
    "        y_start = X_end\n",
    "        y_end = ((i+1)*x_qnotes + y_qnotes) *qnote\n",
    "        X.append(pianoroll[X_start:X_end])\n",
    "        y.append(pianoroll[y_start:y_end])\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bafffb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sampling multiple tracks with func - One Array\n",
    "def multi_sample_pianorolls(pianorolls, qnote = 24, x_qnotes = 192, y_qnotes = 192):\n",
    "    '''pianorolls = output of 'fetching_instrument_pianorolls' function in data.py. \n",
    "    Returns an array concatenating all the samples of n songs.'''\n",
    "    X = []\n",
    "    y = []\n",
    "    for pianoroll in pianorolls:\n",
    "        quarter_notes = int(pianoroll.shape[0]/qnote)\n",
    "        for i in range(int(np.floor(quarter_notes/(x_qnotes+y_qnotes)))):\n",
    "            X_start = i*x_qnotes *qnote\n",
    "            X_end = ((i+1)*x_qnotes) *qnote\n",
    "            y_start = X_end\n",
    "            y_end = ((i+1)*x_qnotes + y_qnotes) *qnote\n",
    "            X.append(pianoroll[X_start:X_end])\n",
    "            y.append(pianoroll[y_start:y_end])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90262205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = multi_sample_pianorolls(pianorolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd035650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 4608, 128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dedbe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 128) 128\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 4608, 128)         32896     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 4608, 128)         32896     \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 4608, 128)         32896     \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 4608, 128)         32896     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4608, 128)         16512     \n",
      "=================================================================\n",
      "Total params: 148,096\n",
      "Trainable params: 148,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 11:12:10.007894: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def init_model(X, y):\n",
    "    input_shape = X[0].shape\n",
    "    output_shape = y[0].shape[1]\n",
    "    print (input_shape, output_shape)\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.SimpleRNN(128, return_sequences=True, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.SimpleRNN(128, return_sequences=True, activation='tanh', input_shape=input_shape))\n",
    "    model.add(layers.SimpleRNN(128, return_sequences=True, activation='tanh', input_shape=input_shape))\n",
    "    model.add(layers.SimpleRNN(128, return_sequences=True, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='tanh'))\n",
    "    model.compile(loss='mse', optimizer=RMSprop(learning_rate=0.001))\n",
    "    return model\n",
    "\n",
    "model = init_model(X, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58371a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 11:12:19.720292: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 79s 4s/step - loss: 128.3334 - val_loss: 141.3727\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 77s 4s/step - loss: 127.8924 - val_loss: 141.0768\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 77s 4s/step - loss: 127.7213 - val_loss: 141.0610\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 78s 4s/step - loss: 127.7196 - val_loss: 141.0306\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 77s 4s/step - loss: 127.7024 - val_loss: 141.0418\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 77s 4s/step - loss: 127.6984 - val_loss: 141.0502\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 77s 4s/step - loss: 127.6958 - val_loss: 141.0300\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 76s 4s/step - loss: 127.6895 - val_loss: 141.0278\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 75s 4s/step - loss: 127.6845 - val_loss: 141.0186\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 76s 4s/step - loss: 127.6771 - val_loss: 141.0101\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience = 2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X, y, validation_split=0.2, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f19fe59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X)\n",
    "pred.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b89ba9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 4608, 128)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_generator.midi import play_pianoroll\n",
    "\n",
    "play_pianoroll(data[0], pred[:15].reshape(15*4608, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6069bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
